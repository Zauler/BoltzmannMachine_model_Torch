{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.parallel \n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASETS\n",
    "movies = pd.read_csv(\"ml-1m/ml-1m/movies.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")\n",
    "users = pd.read_csv(\"ml-1m/ml-1m/users.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")\n",
    "ratings = pd.read_csv(\"ml-1m/ml-1m/ratings.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training set and the testing set\n",
    "training_set = pd.read_csv(\"ml-100k/ml-100k/u1.base\", sep = \"\\t\", header=  None)\n",
    "training_set = np.array(training_set, dtype = \"int\")\n",
    "\n",
    "test_set = pd.read_csv(\"ml-100k/ml-100k/u1.test\", sep = \"\\t\", header=  None)\n",
    "test_set = np.array(test_set, dtype = \"int\")\n",
    "\n",
    "# to obtain the number of users and number of films \n",
    "nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]),max(test_set[:,1])))\n",
    "\n",
    "# convert the data into an array X[u,i] with users u in row and movies i in column \n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1,nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies-1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n",
    "\n",
    "# Convert data to Torch tensors \n",
    "training_set = torch.FloatTensor(training_set) #expect everything to come in rows, that's why we have made a list of lists above.\n",
    "test_set = torch.FloatTensor(test_set)\n",
    "\n",
    "# Convert ratings to binary binary values 1 (Like) or 0 (Dislike):\n",
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the architecture of the neural network (Probabilistic graphical model)\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.rand(1, nh)  #batch and bias as it cannot be one-dimensional\n",
    "        self.b = torch.rand(1, nv) \n",
    "    def sample_h(self,x):         \n",
    "        #x user ratings x = mini_batch_size x nv\n",
    "        wx = torch.mm(x, self.W.t()) # 1 row ( or mini_batch_size ) x nh columns\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation) #probability of hiddent given visible \n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v) #Bernuilli of probability.\n",
    "    def sample_v(self,y):\n",
    "        #y = mini_batch_size x nh  \n",
    "        wy = torch.mm(y, self.W) # 1 row ( or mini_batch_size ) x nv columns\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_h_given_h = torch.sigmoid(activation)  #probability of hiddent given visible \n",
    "        return p_h_given_h, torch.bernoulli(p_h_given_h) #Bernuilli of probability.\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(),phk)).t()\n",
    "        self.b += torch.sum((v0 - vk),0)       #to maintain the dominance\n",
    "        self.a += torch.sum((ph0 - phk ),0) "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: tensor(0.3234)\n",
      "Epoch: 2, Loss: tensor(0.1356)\n",
      "Epoch: 3, Loss: tensor(0.1502)\n",
      "Epoch: 4, Loss: tensor(0.1487)\n",
      "Epoch: 5, Loss: tensor(0.1569)\n",
      "Epoch: 6, Loss: tensor(0.1448)\n",
      "Epoch: 7, Loss: tensor(0.1513)\n",
      "Epoch: 8, Loss: tensor(0.1490)\n",
      "Epoch: 9, Loss: tensor(0.1510)\n",
      "Epoch: 10, Loss: tensor(0.1452)\n"
     ]
    }
   ],
   "source": [
    "nv = len(training_set[0])   #could also be nb_movies\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "\n",
    "rbm = RBM(nv, nh)\n",
    "\n",
    "# Training the rBM\n",
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1): \n",
    "    training_loss = 0 \n",
    "    s = 0. #observation counter\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user+batch_size]\n",
    "        v0 = training_set[id_user:id_user+batch_size]\n",
    "        ph0, _ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk  = rbm.sample_h(vk)\n",
    "            _,vk  = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0] #We do NOT want you to touch the -1, i.e. what users have not seen.\n",
    "        phk, _ =rbm.sample_h(vk)\n",
    "        rbm.train(v0,vk,ph0,phk)\n",
    "        training_loss +=  torch.mean(torch.abs(v0[v0>0]-vk[v0>0]))\n",
    "        s += 1.\n",
    "    print(\"Epoch: \" + str(epoch) +\", Loss: \" + str(training_loss/s)  )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST BM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss: tensor(1.3068)\n",
      "Testing Loss: tensor(0.6534)\n",
      "Testing Loss: tensor(0.4356)\n",
      "Testing Loss: tensor(0.3267)\n",
      "Testing Loss: tensor(0.2614)\n",
      "Testing Loss: tensor(0.2178)\n",
      "Testing Loss: tensor(0.1867)\n",
      "Testing Loss: tensor(0.1634)\n",
      "Testing Loss: tensor(0.1452)\n",
      "Testing Loss: tensor(0.1307)\n",
      "Testing Loss: tensor(0.1188)\n",
      "Testing Loss: tensor(0.1089)\n",
      "Testing Loss: tensor(0.1005)\n",
      "Testing Loss: tensor(0.0933)\n",
      "Testing Loss: tensor(0.0871)\n",
      "Testing Loss: tensor(0.0817)\n",
      "Testing Loss: tensor(0.0769)\n",
      "Testing Loss: tensor(0.0726)\n",
      "Testing Loss: tensor(0.0688)\n",
      "Testing Loss: tensor(0.0653)\n",
      "Testing Loss: tensor(0.0622)\n",
      "Testing Loss: tensor(0.0594)\n",
      "Testing Loss: tensor(0.0568)\n",
      "Testing Loss: tensor(0.0545)\n",
      "Testing Loss: tensor(0.0523)\n",
      "Testing Loss: tensor(0.0503)\n",
      "Testing Loss: tensor(0.0484)\n",
      "Testing Loss: tensor(0.0467)\n",
      "Testing Loss: tensor(0.0451)\n",
      "Testing Loss: tensor(0.0436)\n",
      "Testing Loss: tensor(0.0422)\n",
      "Testing Loss: tensor(0.0408)\n",
      "Testing Loss: tensor(0.0396)\n",
      "Testing Loss: tensor(0.0384)\n",
      "Testing Loss: tensor(0.0373)\n",
      "Testing Loss: tensor(0.0363)\n",
      "Testing Loss: tensor(0.0353)\n",
      "Testing Loss: tensor(0.0344)\n",
      "Testing Loss: tensor(0.0335)\n",
      "Testing Loss: tensor(0.0327)\n",
      "Testing Loss: tensor(0.0319)\n",
      "Testing Loss: tensor(0.0311)\n",
      "Testing Loss: tensor(0.0304)\n",
      "Testing Loss: tensor(0.0297)\n",
      "Testing Loss: tensor(0.0290)\n",
      "Testing Loss: tensor(0.0284)\n",
      "Testing Loss: tensor(0.0278)\n",
      "Testing Loss: tensor(0.0272)\n",
      "Testing Loss: tensor(0.0267)\n",
      "Testing Loss: tensor(0.0261)\n",
      "Testing Loss: tensor(0.0256)\n",
      "Testing Loss: tensor(0.0251)\n",
      "Testing Loss: tensor(0.0247)\n",
      "Testing Loss: tensor(0.0242)\n",
      "Testing Loss: tensor(0.0238)\n",
      "Testing Loss: tensor(0.0233)\n",
      "Testing Loss: tensor(0.0229)\n",
      "Testing Loss: tensor(0.0225)\n",
      "Testing Loss: tensor(0.0221)\n",
      "Testing Loss: tensor(0.0218)\n",
      "Testing Loss: tensor(0.0214)\n",
      "Testing Loss: tensor(0.0211)\n",
      "Testing Loss: tensor(0.0207)\n",
      "Testing Loss: tensor(0.0204)\n",
      "Testing Loss: tensor(0.0201)\n",
      "Testing Loss: tensor(0.0198)\n",
      "Testing Loss: tensor(0.0195)\n",
      "Testing Loss: tensor(0.0192)\n",
      "Testing Loss: tensor(0.0189)\n",
      "Testing Loss: tensor(0.0187)\n",
      "Testing Loss: tensor(0.0184)\n",
      "Testing Loss: tensor(0.0182)\n",
      "Testing Loss: tensor(0.0179)\n",
      "Testing Loss: tensor(0.0177)\n",
      "Testing Loss: tensor(0.0174)\n",
      "Testing Loss: tensor(0.0172)\n",
      "Testing Loss: tensor(0.0170)\n",
      "Testing Loss: tensor(0.0168)\n",
      "Testing Loss: tensor(0.0165)\n",
      "Testing Loss: tensor(0.0163)\n",
      "Testing Loss: tensor(0.0161)\n",
      "Testing Loss: tensor(0.0159)\n",
      "Testing Loss: tensor(0.0157)\n",
      "Testing Loss: tensor(0.0156)\n",
      "Testing Loss: tensor(0.0154)\n",
      "Testing Loss: tensor(0.0152)\n",
      "Testing Loss: tensor(0.0150)\n",
      "Testing Loss: tensor(0.0149)\n",
      "Testing Loss: tensor(0.0147)\n",
      "Testing Loss: tensor(0.0145)\n",
      "Testing Loss: tensor(0.0144)\n",
      "Testing Loss: tensor(0.0142)\n",
      "Testing Loss: tensor(0.0141)\n",
      "Testing Loss: tensor(0.0139)\n",
      "Testing Loss: tensor(0.0138)\n",
      "Testing Loss: tensor(0.0136)\n",
      "Testing Loss: tensor(0.0135)\n",
      "Testing Loss: tensor(0.0133)\n",
      "Testing Loss: tensor(0.0132)\n",
      "Testing Loss: tensor(0.0131)\n",
      "Testing Loss: tensor(0.0129)\n",
      "Testing Loss: tensor(0.0128)\n",
      "Testing Loss: tensor(0.0127)\n",
      "Testing Loss: tensor(0.0126)\n",
      "Testing Loss: tensor(0.0124)\n",
      "Testing Loss: tensor(0.0123)\n",
      "Testing Loss: tensor(0.0122)\n",
      "Testing Loss: tensor(0.0121)\n",
      "Testing Loss: tensor(0.0120)\n",
      "Testing Loss: tensor(0.0119)\n",
      "Testing Loss: tensor(0.0118)\n",
      "Testing Loss: tensor(0.0117)\n",
      "Testing Loss: tensor(0.0116)\n",
      "Testing Loss: tensor(0.0115)\n",
      "Testing Loss: tensor(0.0114)\n",
      "Testing Loss: tensor(0.0113)\n",
      "Testing Loss: tensor(0.0112)\n",
      "Testing Loss: tensor(0.0111)\n",
      "Testing Loss: tensor(0.0110)\n",
      "Testing Loss: tensor(0.0109)\n",
      "Testing Loss: tensor(0.0108)\n",
      "Testing Loss: tensor(0.0107)\n",
      "Testing Loss: tensor(0.0106)\n",
      "Testing Loss: tensor(0.0105)\n",
      "Testing Loss: tensor(0.0105)\n",
      "Testing Loss: tensor(0.0104)\n",
      "Testing Loss: tensor(0.0103)\n",
      "Testing Loss: tensor(0.0102)\n",
      "Testing Loss: tensor(0.0101)\n",
      "Testing Loss: tensor(0.0101)\n",
      "Testing Loss: tensor(0.0100)\n",
      "Testing Loss: tensor(0.0099)\n",
      "Testing Loss: tensor(0.0098)\n",
      "Testing Loss: tensor(0.0098)\n",
      "Testing Loss: tensor(0.0097)\n",
      "Testing Loss: tensor(0.0096)\n",
      "Testing Loss: tensor(0.0095)\n",
      "Testing Loss: tensor(0.0095)\n",
      "Testing Loss: tensor(0.0094)\n",
      "Testing Loss: tensor(0.0093)\n",
      "Testing Loss: tensor(0.0093)\n",
      "Testing Loss: tensor(0.0092)\n",
      "Testing Loss: tensor(0.0091)\n",
      "Testing Loss: tensor(0.0091)\n",
      "Testing Loss: tensor(0.0090)\n",
      "Testing Loss: tensor(0.0090)\n",
      "Testing Loss: tensor(0.0089)\n",
      "Testing Loss: tensor(0.0088)\n",
      "Testing Loss: tensor(0.0088)\n",
      "Testing Loss: tensor(0.0087)\n",
      "Testing Loss: tensor(0.0087)\n",
      "Testing Loss: tensor(0.0086)\n",
      "Testing Loss: tensor(0.0085)\n",
      "Testing Loss: tensor(0.0085)\n",
      "Testing Loss: tensor(0.0084)\n",
      "Testing Loss: tensor(0.0084)\n",
      "Testing Loss: tensor(0.0083)\n",
      "Testing Loss: tensor(0.0083)\n",
      "Testing Loss: tensor(0.0082)\n",
      "Testing Loss: tensor(0.0082)\n",
      "Testing Loss: tensor(0.0081)\n",
      "Testing Loss: tensor(0.0081)\n",
      "Testing Loss: tensor(0.0080)\n",
      "Testing Loss: tensor(0.0080)\n",
      "Testing Loss: tensor(0.0079)\n",
      "Testing Loss: tensor(0.0079)\n",
      "Testing Loss: tensor(0.0078)\n",
      "Testing Loss: tensor(0.0078)\n",
      "Testing Loss: tensor(0.0077)\n",
      "Testing Loss: tensor(0.0077)\n",
      "Testing Loss: tensor(0.0076)\n",
      "Testing Loss: tensor(0.0076)\n",
      "Testing Loss: tensor(0.0076)\n",
      "Testing Loss: tensor(0.0075)\n",
      "Testing Loss: tensor(0.0075)\n",
      "Testing Loss: tensor(0.0074)\n",
      "Testing Loss: tensor(0.0074)\n",
      "Testing Loss: tensor(0.0073)\n",
      "Testing Loss: tensor(0.0073)\n",
      "Testing Loss: tensor(0.0073)\n",
      "Testing Loss: tensor(0.0072)\n",
      "Testing Loss: tensor(0.0072)\n",
      "Testing Loss: tensor(0.0071)\n",
      "Testing Loss: tensor(0.0071)\n",
      "Testing Loss: tensor(0.0071)\n",
      "Testing Loss: tensor(0.0070)\n",
      "Testing Loss: tensor(0.0070)\n",
      "Testing Loss: tensor(0.0070)\n",
      "Testing Loss: tensor(0.0069)\n",
      "Testing Loss: tensor(0.0069)\n",
      "Testing Loss: tensor(0.0068)\n",
      "Testing Loss: tensor(0.0068)\n",
      "Testing Loss: tensor(0.0068)\n",
      "Testing Loss: tensor(0.0067)\n",
      "Testing Loss: tensor(0.0067)\n",
      "Testing Loss: tensor(0.0067)\n",
      "Testing Loss: tensor(0.0066)\n",
      "Testing Loss: tensor(0.0066)\n",
      "Testing Loss: tensor(0.0066)\n",
      "Testing Loss: tensor(0.0065)\n",
      "Testing Loss: tensor(0.0065)\n",
      "Testing Loss: tensor(0.0065)\n",
      "Testing Loss: tensor(0.0064)\n",
      "Testing Loss: tensor(0.0064)\n",
      "Testing Loss: tensor(0.0064)\n",
      "Testing Loss: tensor(0.0063)\n",
      "Testing Loss: tensor(0.0063)\n",
      "Testing Loss: tensor(0.0063)\n",
      "Testing Loss: tensor(0.0063)\n",
      "Testing Loss: tensor(0.0062)\n",
      "Testing Loss: tensor(0.0062)\n",
      "Testing Loss: tensor(0.0062)\n",
      "Testing Loss: tensor(0.0061)\n",
      "Testing Loss: tensor(0.0061)\n",
      "Testing Loss: tensor(0.0061)\n",
      "Testing Loss: tensor(0.0061)\n",
      "Testing Loss: tensor(0.0060)\n",
      "Testing Loss: tensor(0.0060)\n",
      "Testing Loss: tensor(0.0060)\n",
      "Testing Loss: tensor(0.0059)\n",
      "Testing Loss: tensor(0.0059)\n",
      "Testing Loss: tensor(0.0059)\n",
      "Testing Loss: tensor(0.0059)\n",
      "Testing Loss: tensor(0.0058)\n",
      "Testing Loss: tensor(0.0058)\n",
      "Testing Loss: tensor(0.0058)\n",
      "Testing Loss: tensor(0.0058)\n",
      "Testing Loss: tensor(0.0057)\n",
      "Testing Loss: tensor(0.0057)\n",
      "Testing Loss: tensor(0.0057)\n",
      "Testing Loss: tensor(0.0057)\n",
      "Testing Loss: tensor(0.0056)\n",
      "Testing Loss: tensor(0.0056)\n",
      "Testing Loss: tensor(0.0056)\n",
      "Testing Loss: tensor(0.0056)\n",
      "Testing Loss: tensor(0.0055)\n",
      "Testing Loss: tensor(0.0055)\n",
      "Testing Loss: tensor(0.0055)\n",
      "Testing Loss: tensor(0.0055)\n",
      "Testing Loss: tensor(0.0054)\n",
      "Testing Loss: tensor(0.0054)\n",
      "Testing Loss: tensor(0.0054)\n",
      "Testing Loss: tensor(0.0054)\n",
      "Testing Loss: tensor(0.0054)\n",
      "Testing Loss: tensor(0.0053)\n",
      "Testing Loss: tensor(0.0053)\n",
      "Testing Loss: tensor(0.0053)\n",
      "Testing Loss: tensor(0.0053)\n",
      "Testing Loss: tensor(0.0052)\n",
      "Testing Loss: tensor(0.0052)\n",
      "Testing Loss: tensor(0.0052)\n",
      "Testing Loss: tensor(0.0052)\n",
      "Testing Loss: tensor(0.0052)\n",
      "Testing Loss: tensor(0.0051)\n",
      "Testing Loss: tensor(0.0051)\n",
      "Testing Loss: tensor(0.0051)\n",
      "Testing Loss: tensor(0.0051)\n",
      "Testing Loss: tensor(0.0051)\n",
      "Testing Loss: tensor(0.0050)\n",
      "Testing Loss: tensor(0.0050)\n",
      "Testing Loss: tensor(0.0050)\n",
      "Testing Loss: tensor(0.0050)\n",
      "Testing Loss: tensor(0.0050)\n",
      "Testing Loss: tensor(0.0050)\n",
      "Testing Loss: tensor(0.0049)\n",
      "Testing Loss: tensor(0.0049)\n",
      "Testing Loss: tensor(0.0049)\n",
      "Testing Loss: tensor(0.0049)\n",
      "Testing Loss: tensor(0.0049)\n",
      "Testing Loss: tensor(0.0048)\n",
      "Testing Loss: tensor(0.0048)\n",
      "Testing Loss: tensor(0.0048)\n",
      "Testing Loss: tensor(0.0048)\n",
      "Testing Loss: tensor(0.0048)\n",
      "Testing Loss: tensor(0.0048)\n",
      "Testing Loss: tensor(0.0047)\n",
      "Testing Loss: tensor(0.0047)\n",
      "Testing Loss: tensor(0.0047)\n",
      "Testing Loss: tensor(0.0047)\n",
      "Testing Loss: tensor(0.0047)\n",
      "Testing Loss: tensor(0.0047)\n",
      "Testing Loss: tensor(0.0046)\n",
      "Testing Loss: tensor(0.0046)\n",
      "Testing Loss: tensor(0.0046)\n",
      "Testing Loss: tensor(0.0046)\n",
      "Testing Loss: tensor(0.0046)\n",
      "Testing Loss: tensor(0.0046)\n",
      "Testing Loss: tensor(0.0045)\n",
      "Testing Loss: tensor(0.0045)\n",
      "Testing Loss: tensor(0.0045)\n",
      "Testing Loss: tensor(0.0045)\n",
      "Testing Loss: tensor(0.0045)\n",
      "Testing Loss: tensor(0.0045)\n",
      "Testing Loss: tensor(0.0044)\n",
      "Testing Loss: tensor(0.0044)\n",
      "Testing Loss: tensor(0.0044)\n",
      "Testing Loss: tensor(0.0044)\n",
      "Testing Loss: tensor(0.0044)\n",
      "Testing Loss: tensor(0.0044)\n",
      "Testing Loss: tensor(0.0044)\n",
      "Testing Loss: tensor(0.0043)\n",
      "Testing Loss: tensor(0.0043)\n",
      "Testing Loss: tensor(0.0043)\n",
      "Testing Loss: tensor(0.0043)\n",
      "Testing Loss: tensor(0.0043)\n",
      "Testing Loss: tensor(0.0043)\n",
      "Testing Loss: tensor(0.0043)\n",
      "Testing Loss: tensor(0.0042)\n",
      "Testing Loss: tensor(0.0042)\n",
      "Testing Loss: tensor(0.0042)\n",
      "Testing Loss: tensor(0.0042)\n",
      "Testing Loss: tensor(0.0042)\n",
      "Testing Loss: tensor(0.0042)\n",
      "Testing Loss: tensor(0.0042)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0041)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0040)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0039)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0038)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0037)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0036)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0035)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0034)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0033)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0032)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0031)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0030)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0029)\n",
      "Testing Loss: tensor(0.0028)\n"
     ]
    }
   ],
   "source": [
    "# Testing the MBR\n",
    "\n",
    "testing_loss = 0 \n",
    "s = 0. #observation counter\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1] #we are still using information from the training set to fill in the gaps.\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    #for k in range(1): #We have trained it to take K steps and keep the predictions and then only use 1 so that the prediction is more likely to be good.\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h  = rbm.sample_h(v)\n",
    "        _,v  = rbm.sample_v(h)\n",
    "        testing_loss +=  torch.mean(torch.abs(vt[vt>0]-v[vt>0]))\n",
    "        s += 1.\n",
    "        print(\"Testing Loss: \" + str(training_loss/s)  )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurements in the metrics of the model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.5733)\n",
      "epoch: 2 loss: tensor(0.4907)\n",
      "epoch: 3 loss: tensor(0.4982)\n",
      "epoch: 4 loss: tensor(0.5007)\n",
      "epoch: 5 loss: tensor(0.4998)\n",
      "epoch: 6 loss: tensor(0.4992)\n",
      "epoch: 7 loss: tensor(0.4946)\n",
      "epoch: 8 loss: tensor(0.4975)\n",
      "epoch: 9 loss: tensor(0.4980)\n",
      "epoch: 10 loss: tensor(0.4999)\n",
      "test loss: tensor(0.4686)\n"
     ]
    }
   ],
   "source": [
    "############## WITH THE MSE OR MEAN SQUARED ERROR #################\n",
    "\n",
    "#######TRAINING#############\n",
    "nv = len(training_set[0])   #could also be nb_movies\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "\n",
    "rbm = RBM(nv, nh)\n",
    "\n",
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user+batch_size]\n",
    "        v0 = training_set[id_user:id_user+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2)) # RMSE \n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "    \n",
    "    ########################TESTING######################\n",
    "    \n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2)) # RMSE \n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the RMSE, our MBR would give an error around 0.46. But be careful, although it looks similar, don't confuse RMSE and average distance. An RMSE of 0.46 does not mean that the average distance between the prediction and the truth of the dataset is 0.46. In random mode we would end up with an RMSE of around 0.72. An error of 0.46 corresponds to 75% of successful prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
